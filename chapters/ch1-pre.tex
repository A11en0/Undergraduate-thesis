
\chapter{绪论}

随着移动网络时代的到来，各种社交网络 APP 也风靡全球，文本数据不断地产生。这些数据大多是短文本，并且数据规模大，数据信息冗余，我们通常无法直接从中获得有价值的信息。由此，借助计算机，使用数据挖掘技术对这些短文本数据进行数据分析显得尤为重要。

\section{研究背景及意义}
因为短文本的研究价值和其自身的特点，使得国内外研究者们越发重视这面的研究，关于短文本的研究
不断涌现，包括针对短文本的分类\cite{Ge2014Short,Sriram2010Short}和聚类\cite{Rakib2020Enhancement, 杨波2019基于词向量和增量聚类的短文本聚类算法}、主题发现\cite{Hu2018Online,Lee2016Sequential}、特征选择\cite{Xuegang2018A,李太白短文本分类中特征选择算法的研究,Jinbao2020Chinese} 等数据挖
掘算法。为了分析短文本数据中有价值的隐含知识，关于短文本分类的研究价值十分凸显。相比长文本, 短文本自身长度较短, 缺乏语义信息. 导致其有严重稀疏性。
由于整个语言字典中单词数量非常大，以英文来说，可能就能达到20万个左右，而如Twitter这样的社
交网络平台单个文档中单词数最大不能超过140个，这就意味着表示每条短文本的向量中可能仅有几十维甚至几维有值，其余几万维都为零，从而造成短文本
数据在表示形式上的严重稀疏性。 且随着互联网的高速发展, 用短短几万维的向量肯定是不足以表示海
量的短文本数据, 可能需要几十万维甚至几千万维的向量来表示一条短文本, 因此短文本的高维问题也
是处理短文本数据亟需解决的问题之一。 由于短文本数据具有文本长度短，特征高维稀疏等问题，导致
传统的文本分类方法很难有效处理，例如 SVM\cite{vapnik1999an}，随机森林\cite{svetnik2003random}，贝叶斯网络\cite{friedman1997bayesian}等分类方法在处理
长文本上具有很好的效果，但对于短文本本身所具有的特性就很难适应. 针对以上问题, 国内外研究学
者提出的各种解决方案. 通过借助 Web 搜索引擎, 从外部语料库获取文本扩展本
地短文本, 从而缓解文本稀疏性问题\cite{yang1999a}.
用熵来优化改进决策树, 发现数据的隐藏规则\cite{Ali2012Improved} 。 随着机器学习与
数据挖掘技术的发展, 文本分类算法层出不穷, 计算力不断提高。 针对目前研究中所遇到的如特征高
维稀疏等问题也会逐渐得到解决。 但面临即将到来的 5G 时代, 数据量又会有一个甚至几个数量级的提
高， 短文本相应也会有新的问题出现等待解决。

\section{本文主要研究内容}   
\subsection{主要研究内容}
本文面向社交网络的短文本数据流，通过数据挖掘技术，结合机器学习方法，对带有类标签的数据进
 行分析，并从中提取有用的信息。由于社交网络平台提取到的数据往往长度较短，没有足够的语义信息。本文采用
 的数据来源于Twitter，一条Twitter数据通常限制在140个单词以内。对短文本的向量化表示时，
 容易得到的是高纬稀疏的矩阵。这是语言模型自身带来的问题，例如，在使用文本分类任务中的最常见的文本表示方法
词袋模型（Bag-of-Words），也就是最简单的一元的语言模型，通常会采集整个Twitter语料库中出现的单词组成的集合作为词汇表，由于使用的词汇是十分丰富的，达到几万甚至到十几万的量级，而一句话中出现的单词却很少，这样得到的
 短文本向量可能仅仅只有几维或者几十维，其余出现的都是零，从而造成了文本表示上的高维稀疏性。

正是由于这种高维稀疏性，使得传统的文本分类方法在处理时很难做到高效。例如，SVM，KNN
，Bayes等方法在处理长文本问题具有很好的效果，但很难适用到短文本当中。

不仅如此，由于数据是流的形式，数据是持续无限的，并且产生的速度很快， 隐含在数据中的信息就
会随着时间产生迁移，带来严重的概念漂移现象，这种现象会导致模型的准确率下降甚至是失效。由此，
数据高维稀疏和概念漂移是急需处理的问题。

主题模型是一种概率模型，不像传统的空间向量和语言模型那样，只是单纯地考虑文档在词
典空间上的维度，而是引入了主题空间，从而实现了文档在主题空间上的表示。每个主题都是在词典空
间上的概率分布，通过引入主题这个概念，就能很方便地文档进行低维表示，这便相应地可以缓解短文
本数据出现的第一个问题--高维稀疏。另外，主题模型还能够抽取文档中的隐含信息，即主题。使得特
征表示更加精准。基于主题模型的特征表示方法，本文提出了一种带概念漂移检测的集成学习算法。

% 本文采用的数据来源于Twitter，使用Twitter官方提供的“根据关键字搜索”API，从Twitter中获取从
% 2012年11月到2013年1月的数据，一共5个类别。考虑到计算量过大，实验中我们只使用了部分数据。
 % 。获取到的数据会通过一系列的处理如分词、去停用词、向量化表示、主题表示等，考虑到时
 % 间序列数据可能随时间迁移出现的概念漂移现象， 设计出高效可用的集成学习算法，对未知的数据进
 % 行预测和分析。

 搭建一个基于Django框架的Web平台，深度展示了数据挖掘过程中的一
 般步骤，包括信息收集、数据集成、数据清理、数据变换、数据挖掘过程、算法应用以及数据可视化等。其中信息收集使用Twitter官方提供的“根据关键字搜索”API，从Twitter中获取到
 从2012年11月到2013年1月的数据，一共5个类别。考虑到计算量过大，实验中我们只使用了部分数据。

\subsection{组织框架}
本文内容一共分为5个章节，各章节的结构和主要内容如下：

第一章\  绪论，主要介绍了该研究课题的背景、意义、研究内容以及目的，最后简要给出了文章的组织
结构。

第二章\ 相关工作概述，介绍了短文本分类问题以及短文本数据流分类用到的相关技术和方法，概念漂
移相关概念、定义，以及面临的挑战。

第三章\ 本章是本文的核心章节，针对短文本高维稀疏和概念漂移现象，提出了带概念漂移的集成分类
方法，介绍了该算法的设计思路，以及算法构建的流程。

第四章\ 本章节主要介绍平台搭建的相关细节。

第五章\ 总结和展望，对本文提出的方法和出现的问题作出总结与分析，并考虑今后继续研究的方向。

\section{本章小结}
随着互联网技术和通信技术的发展，人们渴望向外界分享信息，社交网络呈现一种爆炸式的增长，
随之而来的数据也不断增加。这些数据大多是短文本数据，对这些短文本数据进行数据分析有十分重要
的价值。在本章节中，首先简要了短文本数据流分类的研究背景和意义，介绍了解决该问题中可能出现的挑战，最后给出了全文组织结构。

%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
